{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(R.matlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df <- readMat('data/spamData.mat')\n",
    "# Names are: ytrain, ytest, Xtrain, Xtest,\n",
    "# all of which are matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(pracma)\n",
    "library(LiblineaR)\n",
    "library(data.table)\n",
    "\n",
    "# Separates out the data into K-fold CV chunks.\n",
    "cv_chunk <- function(x, y, n.folds=10) {\n",
    "    per.fold <- floor(nrow(x) / n.folds)\n",
    "    slices <- c(1, seq(n.folds) * per.fold, nrow(x))\n",
    "    \n",
    "    # Split into the folds\n",
    "    x.folds <- lapply(seq(length(slices) - 1), function(s) x[slices[s]:slices[s+1], ])\n",
    "    y.folds <- lapply(seq(length(slices) - 1), function(s) y[slices[s]:slices[s+1], ])\n",
    "    \n",
    "    # Now we need to create the train/test split\n",
    "    folds <- lapply(seq(length(x.folds)), function(s) {\n",
    "        train.mask <- seq(length(x.folds)) == s\n",
    "        test.mask <- !(train.mask)\n",
    "        \n",
    "        # Create the training/test sets for each fold\n",
    "        y.train <- unlist(y.folds[train.mask])\n",
    "        y.test <- unlist(y.folds[test.mask])\n",
    "        x.train <- rbindlist(lapply(x.folds[train.mask], as.data.frame))\n",
    "        x.test <- rbindlist(lapply(x.folds[test.mask], as.data.frame))\n",
    "        return(list(x.train=x.train, x.test=x.test,\n",
    "                    y.train=as.matrix(y.train), y.test=as.matrix(y.test)))\n",
    "    })\n",
    "    \n",
    "    return(folds)\n",
    "}\n",
    "\n",
    "# Computes the cross-validated MSE for a given model and L2\n",
    "cv_mse <- function(x, y, cost, n.folds=10) {\n",
    "    # Shuffle the input row-wise just in case\n",
    "    rows <- sample(nrow(x))\n",
    "    x <- x[rows, ]; y <- as.matrix(y[rows, ])\n",
    "    \n",
    "    mses <- NULL\n",
    "    for (fold in cv_chunk(x, y, n.folds=n.folds)) {\n",
    "        mses <- c(mses, fit_log(fold$x.train, fold$y.train, cost=cost,\n",
    "                                xnew=fold$x.test, ynew=fold$y.test)$mse)\n",
    "    }\n",
    "    \n",
    "    return(mses)\n",
    "}\n",
    "\n",
    "# Fits an L2-regularized logistic regression model and returns\n",
    "# the fit object and the MSE\n",
    "fit_log <- function(x, y, cost, xnew=NULL, ynew=NULL) {\n",
    "    if (is.null(xnew))\n",
    "        xnew <- x\n",
    "    if (is.null(ynew))\n",
    "        ynew <- y\n",
    "        \n",
    "    fit <- LiblineaR(x, y, cost=cost)\n",
    "    return(list(fit=fit, mse=report_mse(fit, xnew, ynew)))\n",
    "}\n",
    "\n",
    "# Take a fitted logistic regression model, predict on a dataset\n",
    "# and report the MSE.\n",
    "report_mse <- function(fit, x, y) {\n",
    "    preds <- predict(fit, x, proba=TRUE)$probabilities[, 1]\n",
    "    mse <- mean((y - preds) ** 2)\n",
    "    return(mse)\n",
    "}\n",
    "\n",
    "# Compute the one-standard-error rule of picking the best\n",
    "# L2 given a data.frame of L2 and MSEs.\n",
    "one_se_rule <- function(fits) {\n",
    "    mse.cutoff <- min(fits$MSE) + (sd(fits$MSE) / sqrt(length(fits$MSE)))\n",
    "    best.lambda <- fits[which.min(fits$MSE - mse.cutoff), 'L2']\n",
    "    return(best.lambda)\n",
    "}\n",
    "\n",
    "# This function will find the best L2 using CV, and return the fitted model\n",
    "l2_cv_fit <- function(x, y) {    \n",
    "    # Compute the MSEs for a bunch of lambdas\n",
    "    lambdas <- logseq(0.001, 10, 10)\n",
    "    fits <- rbindlist(lapply(lambdas, function(c) {\n",
    "        return(data.frame(L2 = c, MSE = mean(cv_mse(x, y, cost=1. / c, n.folds=10))))\n",
    "    }))\n",
    "    \n",
    "    # Fit the best lambda and return the fitted object and MSE\n",
    "    return(fit_log(x, y, cost=1. / one_se_rule(fits)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Standardize the columns so that they have mean 0 and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Train MSE: 0.0554505061520385 test MSE: 0.0612790983849718\"\n"
     ]
    }
   ],
   "source": [
    "# Compute the means and standard deviations on the training set and use these\n",
    "# computed values on the test set\n",
    "mus <- apply(df$Xtrain, 2, mean, na.rm=TRUE)\n",
    "sds <- apply(df$Xtrain, 2, sd, na.rm=TRUE)\n",
    "\n",
    "Xtrain <- t(apply(df$Xtrain, 1, function(x) (x - mus) / sds))\n",
    "Xtest <- t(apply(df$Xtest, 1, function(x) (x - mus) / sds))\n",
    "    \n",
    "# Run the analysis\n",
    "fit <- l2_cv_fit(Xtrain, df$ytrain)$fit\n",
    "train.mse <- report_mse(fit, Xtrain, df$ytrain)\n",
    "test.mse <- report_mse(fit, Xtest, df$ytest)\n",
    "    \n",
    "print(paste0('Train MSE: ', train.mse, ' test MSE: ', test.mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Transform the features using log(x + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Train MSE: 0.0411775519387855 test MSE: 0.045006475915237\"\n"
     ]
    }
   ],
   "source": [
    "Xtrain <- log(df$Xtrain + 0.1)\n",
    "Xtest <- log(df$Xtest + 0.1)\n",
    "    \n",
    "# Run the analysis\n",
    "fit <- l2_cv_fit(Xtrain, df$ytrain)$fit\n",
    "train.mse <- report_mse(fit, Xtrain, df$ytrain)\n",
    "test.mse <- report_mse(fit, Xtest, df$ytest)\n",
    "    \n",
    "print(paste0('Train MSE: ', train.mse, ' test MSE: ', test.mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Binarize the features using I(x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Train MSE: 0.0557650962537647 test MSE: 0.0607532968837769\"\n"
     ]
    }
   ],
   "source": [
    "Xtrain <- apply(df$Xtrain, 2, function(x) as.numeric(x > 0))\n",
    "Xtest <- apply(df$Xtest, 2, function(x) as.numeric(x > 0))\n",
    "\n",
    "# Run the analysis\n",
    "fit <- l2_cv_fit(Xtrain, df$ytrain)$fit\n",
    "train.mse <- report_mse(fit, Xtrain, df$ytrain)\n",
    "test.mse <- report_mse(fit, Xtest, df$ytest)\n",
    "    \n",
    "print(paste0('Train MSE: ', train.mse, ' test MSE: ', test.mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
